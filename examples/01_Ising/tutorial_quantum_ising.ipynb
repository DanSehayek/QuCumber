{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Reconstruction of a positive wavefunction\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "The following imports are needed to run this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qucumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5ca3e3279920>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqucumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_rbm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBinaryRBM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqucumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantum_reconstruction\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumReconstruction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqucumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtraining_statistics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'qucumber'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from qucumber.binary_rbm import BinaryRBM\n",
    "from qucumber.quantum_reconstruction import QuantumReconstruction\n",
    "from qucumber.positive_wavefunction import PositiveWavefunction\n",
    "\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "\n",
    "import qucumber.utils.data as data\n",
    "\n",
    "import quantum_ising_chain as TFIM # for calculating observables after training. More later...\n",
    "\n",
    "'''\n",
    "#from rbm_tutorial import RBM_Module, BinomialRBM\n",
    "import torch\n",
    "#from observables_tutorial import TFIMChainEnergy, TFIMChainMagnetization\n",
    "import numpy as np\n",
    "import csv\n",
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../../qucumber/')\n",
    "from positive_wavefunction import PositiveWavefunction\n",
    "from quantum_reconstruction import QuantumReconstruction\n",
    "sys.path.append('../../qucumber/utils/')\n",
    "import utils.training_statistics as ts\n",
    "sys.path.append('../../qucumber/utils/ed/')\n",
    "from hamiltonians import *\n",
    "from data_generator import *\n",
    "import quantum_ising_chain as TFIM\n",
    "#import importlib.util\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%matplotlib notebook\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _BinaryRBM_ class in *binary_rbm.py* contains the generic properties of an RBM with a binary visible and hidden layer (e.g. it's effective energy and sampling the hidden and visible layers). \n",
    "\n",
    "The actual quantum wavefunction reconstruction occurs in the _QuantumReconstruction_ class in *quantum_reconstruction.py*. A _QuantumReconstruction_ object is initialized with a neural network state (in this case, a PositiveWavefunction object).\n",
    "\n",
    "*callbacks.py* contains functions that allow the user to evaluate the quality of the training (i.e. based on the fidelity or KL divergence).\n",
    "\n",
    "## Training\n",
    "\n",
    "Let's beging with training the RBM on a positive wavefunction. We consider the quantum Ising model with Hamiltonian $H=-J\\sum_{\\langle i j \\rangle} S^z_i S^z_j - h \\sum_i S^x_i$\n",
    "at its quantum critical point $h/J=1$.  The training data has been generated and is contained in the file *tfim1d_N10_train_samples.txt*.  It contains 10,000 measurements of the $S^z$ states of 10 qubits, represented as zeros or ones.\n",
    "\n",
    "To evaluate how well the RBM is training, we compute the fidelity, $|\\langle \\psi|\\psi_{\\rm RBM} \\rangle|^2$, between the true wavefunction of the system and the wavefunction the RBM reconstructs. First, we need to load our training data and the true wavefunction of this system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples_path = 'tfim1d_train_samples.txt'\n",
    "psi_path           = 'tfim1d_psi.txt'\n",
    "\n",
    "train_samples,target_psi = data.load_data(tr_sam_path,psi_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following arguments are required to construct a **PositiveWavefunction** neural network state:\n",
    "\n",
    "1. **The number of visible units**. This is 10 for the case of our dataset.\n",
    "2. **The number of hidden units in the hidden layer of the RBM**. This number is set to the number of visible units by default (10 in the case of our dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv = train_samples.shape[-1]\n",
    "nh = nv\n",
    "\n",
    "nn_state = PositiveWavefunction(num_visible=nv,num_hidden=nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can specify the parameters of the training process:\n",
    "\n",
    "1. **epochs**: the number of epochs, i.e. training cycles that will be performed; 1000 should be fine\n",
    "2. **batch_size**: the number of data points used in the positive phase of the gradient; we'll go with 100\n",
    "3. **num_chains**: the number of data points used in the negative phase of the gradient. Keeping this larger than the *batch_size* is preferred; we'll go with 200\n",
    "4. **CD**: the number of contrastive divergence steps; CD=1 seems to be good enough in most cases\n",
    "5. **lr**: the learning rate; we will use a learning rate of 0.01 here\n",
    "6. **log_every**: how often you would like the program to update you during the training; we choose 50 - that is, every 50 epochs the program will print out the fidelity. This parameter is required in the *MetricEvaluator*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs     = 1000\n",
    "batch_size = 100\n",
    "num_chains = 200\n",
    "CD         = 1\n",
    "lr         = 0.01\n",
    "log_every  = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we initialize the parameters of the *PositiveWavefunction* and the *MetricEvaluator*, we can now begin training. Our *QuantumReconstruction* object, *qr* (see below), contains a function called *fit* that executes the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'qr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-557fd7ad3b4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogbar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'qr' is not defined"
     ]
    }
   ],
   "source": [
    "nn_state.space = nn_state.generate_Hilbert_space(nv) # generate the entire visible space of the system.\n",
    "callbacks      = [MetricEvaluator(log_every,{'Fidelity':ts.fidelity,'KL':ts.KL},target_psi=target_psi)]\n",
    "\n",
    "qr = QuantumReconstruction(nn_state)\n",
    "\n",
    "qr.fit(train_samples, epochs, batch_size, num_chains, CD,lr, progbar=False,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Training \n",
    "\n",
    "After training the RBM, the *fit* function will have stored the trained weights and biases. Now, we can generate samples from the trained RBM and calculate physical observables.\n",
    "\n",
    "We have created an example python file called *quantum_ising_chain.py* that takes advantage of QuCumber's built in *observables* module to calculate the energy of a TFIM. A tutorial for utilizing the *observables* module for different systems (i.e. not a TFIM) will be supplied in the near future.\n",
    "\n",
    "*quantum_ising_chain* (imported as *TFIM*) comprises of a class called *TransverseFieldIsingChain*. A *TransverseFieldIsingChain* is instantiated with the following arguments:\n",
    "\n",
    "1. **hx**: This is the *h* value of the TFIM (1 in the case of our dataset).\n",
    "2. **n_measurements**: The number of samples to be generated from the trained RBM. These samples will be used to calculate the observables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TFIM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2495bc171335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_measurements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfim\u001b[0m           \u001b[0;34m=\u001b[0m \u001b[0mTFIM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTransverseFieldIsingChain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_measurements\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'TFIM' is not defined"
     ]
    }
   ],
   "source": [
    "n_measurements = 50000\n",
    "hx             = 1\n",
    "tfim           = TFIM.TransverseFieldIsingChain(hx,n_measurements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To go ahead and calculate the energy and magnetization of the 50,000 generated samples, the *tfim* object has a function called *run* which will output a dictionary containing the energy (key: 'energy') and the magnetization (key: 'sigmaZ'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation = tfim.Run(nn_state,n_eq=200, show_convergence=True)\n",
    "\n",
    "step = list(range(n_eq))\n",
    "\n",
    "Energy     = simulation['energy']\n",
    "err_energy = np.std(Energy)/np.sqrt(Energy.shape[0])\n",
    "\n",
    "sigmaZ = simulation['sigmaZ']\n",
    "err_sZ = np.std(sigmaZ)/np.sqrt(sigmaZ.shape[0])\n",
    "\n",
    "ax1 = plt.axes()\n",
    "ax1.plot(step, Energy, color='red')\n",
    "ax1.fill_between(step, Energy-err_energy, Energy+err_energy, color='red', alpha=0.4) \n",
    "#ax1.plot(step, true_energy, color='black')\n",
    "ax1.grid()\n",
    "ax1.set_xlim(0,n_eq)\n",
    "ax1.set_xlabel('CD Step')\n",
    "ax1.set_ylabel('Energy')\n",
    "\n",
    "ax2 = plt.axes()\n",
    "ax2.plot(step, sigmaZ, color='red')\n",
    "ax2.fill_between(step, sigmaZ-err_sZ, sigmaZ+err_sZ, color='red', alpha=0.4) \n",
    "#ax2.plot(step_list, true_mag, color='black')\n",
    "ax2.grid()\n",
    "ax2.set_xlim(0,n_eq)\n",
    "ax2.set_xlabel('CD Step')\n",
    "ax2.set_ylabel('Magnetization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a brief transient period in each observable, before the state of the machine \"warms up\" to equilibrium.  After that, the values fluctuate around the mean.  The exact value for the energy is -1.2785, and for the magnetization is 0.7072."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
