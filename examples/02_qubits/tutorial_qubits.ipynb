{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-qubit complex wavefunction\n",
    "\n",
    "In this tutorial, we use QuCumber reconstruct the most likely wavefunction from measurements of tow qubits. In constrast with the TFIM tutorial, this wavefunction as an amplitude and a phase, so it cannot be written as a completely positive real wavefunction in any basis.\n",
    "\n",
    "### Two qubits\n",
    "The two qubits are \n",
    "\\begin{equation}\n",
    "            |\\psi \\rangle = \\alpha |00\\rangle + \\beta | 01\\rangle + \\gamma |10\\rangle + \\delta 11\\rangle\n",
    "\\end{equation}\n",
    "where $\\alpha, \\beta, \\gamma, \\delta$ we want to approximate. The exact values used for this tutorial are in qubits_psi.txt, and are \n",
    "\\begin{equation}\n",
    "\\alpha =0.2860859781  + 0.0538594435 i \\\\\n",
    "\\beta = 0.3686925645 - 0.3022891852 i \\\\\n",
    "\\gamma = -0.1672402652 - 0.3528898162 i \\\\\n",
    "\\delta = -0.5658788296 - 0.4639198598 i\n",
    "\\end{equation}\n",
    "\n",
    "##### Code \n",
    "As before, we load the required Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from qucumber.nn_states import ComplexWavefunction\n",
    "from qucumber.callbacks import MetricEvaluator\n",
    "\n",
    "import qucumber.utils.training_statistics as ts\n",
    "import qucumber.utils.data as data\n",
    "import qucumber.utils.cplx as cplx\n",
    "import qucumber.utils.unitaries as unitaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data\n",
    "\n",
    "The training data for a complex wavefunction consists of two file. Firstly, the basis which are measured must be listed. In our example, this is in \"qubits_train_bases.txt\" Secondly, we need the values of the measurements (0, 1) from measurement with those opterators. This is included in \"ubits_train.txt\"and we encourage the reader to take a look at both files to see the format. \n",
    "\n",
    "We also need a list of all the unique basis measurements from the \"quits_train_bases.txt\"file. This can be easily found with numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.loadtxt(\"qubits_train_bases.txt\", dtype=str)\n",
    "bases = np.unique(a, axis=0)\n",
    "bases = [\"\".join(bases[i, :]) for i in range(bases.shape[0])]\n",
    "bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The remainder of the training data can be loaded with the utility function qucumber.utils.data.load_data(). This function simply read the .txt files, and converts them to torch tensors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"qubits_train.txt\"\n",
    "train_bases_path = \"qubits_train_bases.txt\"\n",
    "psi_path = \"qubits_psi.txt\"\n",
    "train, psi, train_bases = data.load_data(train_path, psi_path, train_bases_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To construct a **ComplexWavefunction** neural network state we need to create a dictionary that contains the unitaries that have been applied during the measurements. In our case this were the unitaries $\\mathbb{1}$, $H$, $K$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unitary_dict = unitaries.create_dict()\n",
    "\"\"\"If you would like to add your own quantum gates from your experiment to \n",
    "   \"unitary_dict\", do:\n",
    "   unitary_dict = unitaries.create_dict(name='your_name', \n",
    "                                        unitary=torch.tensor([[real part], \n",
    "                                                              [imaginary part]], \n",
    "                                                             dtype=torch.double)\n",
    "                                                             \n",
    "   For example: \n",
    "   unitaries = unitary_library.create_dict(name='qucumber', \n",
    "                                           unitary=torch.tensor([ [[1.,0.],[0.,1.]] \n",
    "                                                                  [[0.,0.],[0.,0.]] ], \n",
    "                                                                dtype=torch.double))\n",
    "                                                                                             \n",
    "   By default, unitary_library.create_dict() contains the idenity matrix and the \n",
    "   hadamard and K gates with keys Z, X and Y, respectively.\n",
    "\"\"\"\n",
    "\n",
    "unitary_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of visible units is equal to the number of qubits or the length of a training sample. The number of hidden units is set equal to the number of visible units for a neuron density of $\\alpha=1$.\n",
    "\n",
    "Again GPU computing is supported by setting  \"gpu = True\" in ComplexWavefunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state = ComplexWavefunction(num_visible=2, num_hidden=2, unitary_dict=unitary_dict, gpu=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate how the RBM is training, we will compute the full KL divergence and the fidelity between the true wavefunction of the system and the wavefunction the RBM reconstructs.\n",
    "This can be done by initializing the parameters of the **ComplexWavefunction** and the **MetricEvaluator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_every = 10\n",
    "\n",
    "nn_state.space = nn_state.generate_hilbert_space(2)\n",
    "callbacks = [\n",
    "    MetricEvaluator(\n",
    "        log_every,\n",
    "        {\"Fidelity\": ts.fidelity, \"KL\": ts.KL},\n",
    "        target_psi=psi,\n",
    "        bases=bases,\n",
    "        verbose=True,\n",
    "        space=nn_state.space,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After initializing everything we can start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nn_state.fit(\n",
    "    train,\n",
    "    epochs=100,\n",
    "    pos_batch_size=50,\n",
    "    neg_batch_size=10,\n",
    "    lr=1e-2,\n",
    "    k=2,\n",
    "    input_bases=train_bases,\n",
    "    progbar=True,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Training \n",
    "\n",
    "After the training we can calculate state fidelity, observables or sample from the complex wavefunction\n",
    "the same way we did from the real-positive wavefunction. However, one has to keep in mind that the sampling only works in the Z basis.\n",
    "\n",
    "To sample from a trained complex wavefunction we define the number of samples *num_samples* we want to draw and the number of contrastive divergence steps *CD*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2000\n",
    "CD = 200\n",
    "\n",
    "samples = nn_state.sample(num_samples, CD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also analogous to the positive real wavefunction we can save and load the RBM parameters and the newly generated samples using the *save* function within the ComplexWavefunction object and save additional quantities like e.g. *the samples* to the same file with *metadata*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_state.save(\"saved_parameters.pkl\", metadata={\"Samples\": samples})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
