{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rbm import RBM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training and validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = np.loadtxt('../c++/training_data.txt')\n",
    "target_psi = np.loadtxt('../c++/target_psi.txt')\n",
    "\n",
    "train_set.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the RBM with the same number of hidden and visible units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm = RBM(num_visible=train_set.shape[-1],\n",
    "          num_hidden=train_set.shape[-1],\n",
    "          seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train the RBM for 200 epochs with a batch size of 25. During training we'll record the overlap and average negative log likelihood of the model against the validation data every 10 epochs.\n",
    "\n",
    "For reference, the formula for the overlap is as follows:\n",
    "\n",
    "$$\\sum_\\vec{v} \\psi\\left(\\vec{v}\\right)\\sqrt{p\\left(\\vec{v}\\right)}$$\n",
    "\n",
    "This is essentially an estimate of the sum over the entire probability mass function defined by $\\psi^2$. Thus, we want it to be close $1$.\n",
    "\n",
    "First, we'll take a look at the RBM.train method's documentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method train in module rbm:\n",
      "\n",
      "train(data, target, epochs, batch_size, k=1, persistent=False, persist_from=0, lr=0.001, momentum=0.9, method='sgd', l1_reg=0, l2_reg=0, log_every=10, progbar=False, **kwargs) method of rbm.RBM instance\n",
      "    Train the RBM\n",
      "    \n",
      "    data -- the training data\n",
      "    target -- the validation data (wavefunction values)\n",
      "    epochs -- number of epochs to train for\n",
      "    batch_size -- size of each mini-batch\n",
      "    k -- number of Contrastive Divergence steps (default 1)\n",
      "    persistent -- whether to use PCD as opposed to CD\n",
      "                  (default False)\n",
      "    persist_from -- use CD first then start using PCD after\n",
      "                    this many epochs; ignored if `persistent`\n",
      "                    is False (default 0)\n",
      "    lr -- the learning rate; can be a float or a function that\n",
      "          takes the epoch number and returns a float (default 1e-3)\n",
      "    momentum -- the momentum parameter; can be a float or a\n",
      "          function that takes the epoch number and returns\n",
      "          a float; ignored if method is either \"sgd\" or \"adam\"\n",
      "          (default 0.9)\n",
      "    method -- the parameter update method; can be any of:\n",
      "              \"adam\", \"nesterov\", \"momentum\", or \"sgd\"\n",
      "              (default \"sgd\")\n",
      "    l1_reg -- the l1 regularization parameter (default 0)\n",
      "    l2_reg -- the l2 regularization parameter (default 0)\n",
      "    log_every -- how often the validation statistics are recorded\n",
      "                 in epochs (default 10)\n",
      "    progbar -- whether to display a progress bar; can be a boolean\n",
      "               or \"notebook\" for displaying progress bars in a\n",
      "               jupyter notebook (default False)\n",
      "    **kwargs -- extra keyword arguments passed to the parameter\n",
      "                update function; refer to `rbm_grad_updates.py`\n",
      "                for more info\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rbm.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch =    0; NLL per training example =   7.46581103; Overlap =   0.49697722\n",
      "Epoch =   10; NLL per training example =   4.59784933; Overlap =   0.98055360\n",
      "Epoch =   20; NLL per training example =   4.55782278; Overlap =   0.98951308\n",
      "Epoch =   30; NLL per training example =   4.56248325; Overlap =   0.98815823\n",
      "Epoch =   40; NLL per training example =   4.60590591; Overlap =   0.97869122\n",
      "Epoch =   50; NLL per training example =   4.56020164; Overlap =   0.98902553\n",
      "Epoch =   60; NLL per training example =   4.55404177; Overlap =   0.98922637\n",
      "Epoch =   70; NLL per training example =   4.63949484; Overlap =   0.97081105\n",
      "Epoch =   80; NLL per training example =   4.54972841; Overlap =   0.98983613\n",
      "Epoch =   90; NLL per training example =   4.56783523; Overlap =   0.98558907\n",
      "Epoch =  100; NLL per training example =   4.52903160; Overlap =   0.99592382\n",
      "Epoch =  110; NLL per training example =   4.52660564; Overlap =   0.99648050\n"
     ]
    }
   ],
   "source": [
    "log_every = 10 # log and record validation metrics every 10 epochs\n",
    "nll_list, overlap_list = rbm.train(train_set, target_psi, \n",
    "                                   epochs=200,\n",
    "                                   batch_size=25, \n",
    "                                   k=3,\n",
    "                                   lr=(lambda ep: 0.1 if ep < 100 else 1e-4), \n",
    "                                   l1_reg=0, \n",
    "                                   l2_reg=0,\n",
    "                                   method=\"sgd\",\n",
    "                                   log_every=log_every,\n",
    "                                   progbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how the average negative log likelihood and the overlap changed during training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(10, 10))\n",
    "ax1.plot(log_every * np.arange(len(nll_list)), np.array(nll_list) / len(train_set), 'b')\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"NLL per training example\", color='b')\n",
    "ax1.tick_params('y', colors='b')\n",
    "ax1.set_xlim(0, log_every * (len(nll_list)-1))\n",
    "ax1.axvline(x=100, linestyle=':', color='g') # plot when the learning rate switches\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.plot(log_every * np.arange(len(overlap_list)), overlap_list, 'r')\n",
    "ax2.set_ylabel('Overlap', color='r')\n",
    "ax2.tick_params('y', colors='r')\n",
    "ax2.axhline(y=1, xmin=0, xmax=len(overlap_list), linestyle=':', color='r') # maximum overlap\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save the model for later use. Note that the model's internal random state is also saved along with the weights and biases, thus we can expect the saved RBM to produce the exact same sampled as the RBM currently in use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbm.save(\"./demo_model.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rbm = RBM.load(\"./demo_model.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample both the original and the loaded RBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1 = rbm.sample(k=100, n_samples=10) \n",
    "sample2 = new_rbm.sample(k=100, n_samples=10)\n",
    "sample1, sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(sample1, sample2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
